import React, { useState, useRef, useEffect } from "react";

export default function App() {
  const [recording, setRecording] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [quranText, setQuranText] = useState([]);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const intervalRef = useRef(null);
  const pageNumber = 2; // ØµÙØ­Ø© Ù„Ù„ØªØ¬Ø±Ø¨Ø©

  // Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙØ­Ø© Ù…Ù† API
  useEffect(() => {
    fetch(`https://api.alquran.cloud/v1/page/${pageNumber}/quran-uthman`)
      .then((res) => res.json())
      .then((data) => {
        if (data.data && data.data.ayahs) {
          setQuranText(data.data.ayahs);
        }
      })
      .catch((err) => console.error(err));
  }, []);

  // Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorderRef.current = new MediaRecorder(stream);
      audioChunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        processAudio();
      };

      mediaRecorderRef.current.start();

      // ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙƒÙ„ Ø«Ø§Ù†ÙŠØªÙŠÙ†
      intervalRef.current = setInterval(() => {
        if (
          mediaRecorderRef.current &&
          mediaRecorderRef.current.state === "recording"
        ) {
          mediaRecorderRef.current.stop();
          mediaRecorderRef.current.start();
        }
      }, 2000);

      setRecording(true);
    } catch (err) {
      console.error("Microphone error:", err);
    }
  };

  // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      clearInterval(intervalRef.current);
    }
    setRecording(false);
  };

  // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡ Ù„Ù€ Wit.ai
  const processAudio = async () => {
    const blob = new Blob(audioChunksRef.current, { type: "audio/webm" }); // Ø¬Ø±Ø¨ webm
    audioChunksRef.current = [];

    const formData = new FormData();
    formData.append("file", blob, "speech.webm");

    try {
      const response = await fetch("https://api.wit.ai/speech?v=20210928", {
        method: "POST",
        headers: {
          Authorization: "Bearer WMFB2ARELBKH5LPN3U3RO65WNJFZ2UN7",
        },
        body: blob, // Ù†Ø¨Ø¹Øª Ø§Ù„Ø¨ÙˆØ¯ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©
      });

      const text = await response.text();
      console.log("Wit.ai response:", text);
      setTranscript(text); // Ø¹Ù„Ø´Ø§Ù† ÙŠØ¸Ù‡Ø± ÙÙŠ h1
    } catch (err) {
      console.error("Wit.ai error:", err);
    }
  };

  return (
    <div className="p-4">
      <h1>ğŸ“– Quran Page {pageNumber}</h1>
      {quranText.map((ayah) => (
        <p key={ayah.number} style={{ direction: "rtl", fontSize: "20px" }}>
          {ayah.text}
        </p>
      ))}

      <div className="mt-4">
        {!recording ? (
          <button
            onClick={startRecording}
            className="bg-green-500 text-white px-4 py-2 rounded"
          >
            â–¶ï¸ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
          </button>
        ) : (
          <button
            onClick={stopRecording}
            className="bg-red-500 text-white px-4 py-2 rounded"
          >
            â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„
          </button>
        )}
      </div>

      <h1 className="mt-4">ğŸ¤ Wit.ai Response:</h1>
      <pre style={{ whiteSpace: "pre-wrap" }}>{transcript}</pre>
    </div>
  );
}
